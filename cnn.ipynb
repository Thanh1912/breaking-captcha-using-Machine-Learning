{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "chars_list = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "chars_dict = {c: chars_list.index(c) for c in chars_list}\n",
    "\n",
    "char_img_paths = glob('data/chars/*.jpg')\n",
    "char_img_paths[:5]\n",
    "\n",
    "\n",
    "np_images = []\n",
    "raw_labels = []\n",
    "\n",
    "for char_img_path in char_img_paths:\n",
    "    np_image = cv2.imread(char_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    raw_label = char_img_path.split('/')[-1].split('-')[0]\n",
    "    \n",
    "    np_images.append(np_image)\n",
    "    raw_labels.append(chars_dict[raw_label])\n",
    "np_images = np.array(np_images) / 255.0\n",
    "raw_labels = np.array(raw_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5056, 36, 30), (5056,), 36)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_images.shape, raw_labels.shape, len(chars_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_images = np_images.reshape(-1, 36, 30, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras._impl.keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "vec_labels = to_categorical(raw_labels, num_classes=36)\n",
    "vec_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = \\\n",
    "    train_test_split(np_images, vec_labels, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (4550, 36, 30, 1) (1 channels).\n",
      "Epoch 1/20\n",
      "1s - loss: 2.8741 - acc: 0.2078 - val_loss: 0.6890 - val_acc: 0.8419\n",
      "Epoch 2/20\n",
      "0s - loss: 0.9416 - acc: 0.7059 - val_loss: 0.1417 - val_acc: 0.9723\n",
      "Epoch 3/20\n",
      "0s - loss: 0.4378 - acc: 0.8610 - val_loss: 0.0762 - val_acc: 0.9822\n",
      "Epoch 4/20\n",
      "0s - loss: 0.2500 - acc: 0.9148 - val_loss: 0.0669 - val_acc: 0.9921\n",
      "Epoch 5/20\n",
      "0s - loss: 0.1937 - acc: 0.9380 - val_loss: 0.0511 - val_acc: 0.9941\n",
      "Epoch 6/20\n",
      "0s - loss: 0.1655 - acc: 0.9489 - val_loss: 0.0535 - val_acc: 0.9921\n",
      "Epoch 7/20\n",
      "0s - loss: 0.1341 - acc: 0.9570 - val_loss: 0.0487 - val_acc: 0.9941\n",
      "Epoch 8/20\n",
      "0s - loss: 0.1275 - acc: 0.9625 - val_loss: 0.0397 - val_acc: 0.9941\n",
      "Epoch 9/20\n",
      "\n",
      "Epoch 00008: reducing learning rate to 0.0005000000237487257.\n",
      "0s - loss: 0.1156 - acc: 0.9628 - val_loss: 0.0444 - val_acc: 0.9941\n",
      "Epoch 10/20\n",
      "0s - loss: 0.0828 - acc: 0.9749 - val_loss: 0.0433 - val_acc: 0.9941\n",
      "Epoch 11/20\n",
      "0s - loss: 0.0665 - acc: 0.9792 - val_loss: 0.0384 - val_acc: 0.9941\n",
      "Epoch 12/20\n",
      "\n",
      "Epoch 00011: reducing learning rate to 0.0002500000118743628.\n",
      "0s - loss: 0.0666 - acc: 0.9807 - val_loss: 0.0384 - val_acc: 0.9941\n",
      "Epoch 13/20\n",
      "0s - loss: 0.0602 - acc: 0.9846 - val_loss: 0.0420 - val_acc: 0.9941\n",
      "Epoch 14/20\n",
      "0s - loss: 0.0461 - acc: 0.9881 - val_loss: 0.0401 - val_acc: 0.9960\n",
      "Epoch 15/20\n",
      "0s - loss: 0.0478 - acc: 0.9863 - val_loss: 0.0383 - val_acc: 0.9941\n",
      "Epoch 16/20\n",
      "0s - loss: 0.0524 - acc: 0.9857 - val_loss: 0.0405 - val_acc: 0.9941\n",
      "Epoch 17/20\n",
      "0s - loss: 0.0427 - acc: 0.9882 - val_loss: 0.0361 - val_acc: 0.9960\n",
      "Epoch 18/20\n",
      "\n",
      "Epoch 00017: reducing learning rate to 0.0001250000059371814.\n",
      "0s - loss: 0.0331 - acc: 0.9908 - val_loss: 0.0380 - val_acc: 0.9960\n",
      "Epoch 19/20\n",
      "0s - loss: 0.0421 - acc: 0.9895 - val_loss: 0.0363 - val_acc: 0.9960\n",
      "Epoch 20/20\n",
      "0s - loss: 0.0393 - acc: 0.9888 - val_loss: 0.0402 - val_acc: 0.9941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras._impl.keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.python.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import ReduceLROnPlateau\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "def random_batch(x_train, y_train, batch_size):\n",
    "    rnd_indices = np.random.randint(0, len(x_train), batch_size)\n",
    "    x_batch = x_train[rnd_indices]\n",
    "    y_batch = y_train[rnd_indices]\n",
    "    return x_batch, y_batch\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, 5, padding='same', activation='relu', input_shape=(36, 30, 1)))\n",
    "model.add(Conv2D(32, 5, padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, 3, padding='Same', activation='relu'))\n",
    "model.add(Conv2D(64,3, padding='Same', activation='relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(36, activation='softmax'))\n",
    "optimizer = Adam()\n",
    "model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "epochs = 20 \n",
    "batch_size = 80\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=5,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(x_train)\n",
    "history = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (x_val,y_val),\n",
    "                              verbose = 2, steps_per_epoch=x_train.shape[0] // batch_size\n",
    "                              , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
